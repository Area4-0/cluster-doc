{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction # Cluster 4.0 provides a set of machines to be used to run research experiments. These machines are located in campus of Cesena. Their resources are shared among all students and researchers, and exploitable through a cluster management system. At the moment, the cluster management system is based on Docker Swarm, and available through the Portainer Dashboard . Portainer is a service that enables users to deploy containers in clusters through a web interface, providing also an access management system. Portainer manages many environments (i.e. clusters), and at the moment there is only one cluster available on the platform, which are visible through the Cluster Visualizer section inside the web dashboard. All cluster\u2019s machines are Linux servers. Seealso To use this service, please read the quickstart section . Note The machines are not accessible from the outside, you need to be connected to the campus of Cesena's VPN network to access them. Note Machines' resources are shared among all researchers, so unused containers should be removed to leave resources available to other users.","title":"Introduction"},{"location":"#introduction","text":"Cluster 4.0 provides a set of machines to be used to run research experiments. These machines are located in campus of Cesena. Their resources are shared among all students and researchers, and exploitable through a cluster management system. At the moment, the cluster management system is based on Docker Swarm, and available through the Portainer Dashboard . Portainer is a service that enables users to deploy containers in clusters through a web interface, providing also an access management system. Portainer manages many environments (i.e. clusters), and at the moment there is only one cluster available on the platform, which are visible through the Cluster Visualizer section inside the web dashboard. All cluster\u2019s machines are Linux servers. Seealso To use this service, please read the quickstart section . Note The machines are not accessible from the outside, you need to be connected to the campus of Cesena's VPN network to access them. Note Machines' resources are shared among all researchers, so unused containers should be removed to leave resources available to other users.","title":"Introduction"},{"location":"good-practices/","text":"Good Practices # Users can deploy their own experiments in the cluster on which they are granted to work. Cluster resources are shared among all users, so it is important to follow some good practices to avoid conflicts with them. Each container should be run with a unique name, following the pattern: <name>.<surname>-<purpose> . Each container could possibly reserve all the resources of a node of the cluster, so it is important to specify only the amount of resources that are really needed to run the experiments. Each container allocation is temporary, this means that if not needed at a certain moment, it must be stopped and removed. This is important to avoid wasting resources and to allow other users to run their experiments. Each Sunday at 1:30 AM cluster machines are configured to perform automatic updates, sometimes this operation requires the reboot of the machine. To avoid the loss of data, it is important to save the data on a persistent volume. Persistency # By default, all the data generated inside a container is lost when the container is stopped and removed (or restarted). To avoid this, it is possible to configure the container to use a Docker persistent volume. Basically, a persistent volume is a directory on the host machine that could be mounted into a container. Each cluster's user is granted to use a persistent volume, provided by the cluster administrators. To use a persistent volume when running a container, the user must specify the volume name and the mount path inside of the container. Seealso See Docker Volumes for more information about Docker volumes.","title":"Good Practices"},{"location":"good-practices/#good-practices","text":"Users can deploy their own experiments in the cluster on which they are granted to work. Cluster resources are shared among all users, so it is important to follow some good practices to avoid conflicts with them. Each container should be run with a unique name, following the pattern: <name>.<surname>-<purpose> . Each container could possibly reserve all the resources of a node of the cluster, so it is important to specify only the amount of resources that are really needed to run the experiments. Each container allocation is temporary, this means that if not needed at a certain moment, it must be stopped and removed. This is important to avoid wasting resources and to allow other users to run their experiments. Each Sunday at 1:30 AM cluster machines are configured to perform automatic updates, sometimes this operation requires the reboot of the machine. To avoid the loss of data, it is important to save the data on a persistent volume.","title":"Good Practices"},{"location":"good-practices/#persistency","text":"By default, all the data generated inside a container is lost when the container is stopped and removed (or restarted). To avoid this, it is possible to configure the container to use a Docker persistent volume. Basically, a persistent volume is a directory on the host machine that could be mounted into a container. Each cluster's user is granted to use a persistent volume, provided by the cluster administrators. To use a persistent volume when running a container, the user must specify the volume name and the mount path inside of the container. Seealso See Docker Volumes for more information about Docker volumes.","title":"Persistency"},{"location":"quickstart/","text":"Quickstart # Prerequisites # The important aspects that need to be known, at least on a basic level, by cluster users are: Docker (Documentation here - the basic commands are fine) DockerSwarm Portainer (Documentation here that focus on the user-side concepts and how to deploy containers) Jupyter notebook (Google returns endless resources on this topic, for instance: https://www.dataquest.io/blog/jupyter-notebook-tutorial/ , https://towardsdatascience.com/a-beginners-tutorial-to-jupyter-notebooks-1b2f8705888a ) Note Consider reading https://unibo-spe.github.io/09-containerization Use the cluster # Request access to the VPN and to the required cluster, here is described how to do it. Configure your environment to use the VPN, following the guide received by email. Go to https://andromeda.apice.unibo.it Select an environment (i.e. a cluster) from the available ones on which launch containers Launch your Docker container following good practices . Warning Each machine is configured to run updates every Sunday at 1:30 AM. Sometimes, the update process requires a reboot of the machine. If this happens, the machine will be unavailable for a few minutes. If you are running a job, it will be interrupted and you will have to restart it. Please, follow the persistency good practices in order to save your experiments results in a persistent volume. Note The connection is provided by internal SSL certifiates, modern browsers try to block the connection to them. You have to explicitly declare, the first time you enter the URL described above, that you want to access the website.","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#prerequisites","text":"The important aspects that need to be known, at least on a basic level, by cluster users are: Docker (Documentation here - the basic commands are fine) DockerSwarm Portainer (Documentation here that focus on the user-side concepts and how to deploy containers) Jupyter notebook (Google returns endless resources on this topic, for instance: https://www.dataquest.io/blog/jupyter-notebook-tutorial/ , https://towardsdatascience.com/a-beginners-tutorial-to-jupyter-notebooks-1b2f8705888a ) Note Consider reading https://unibo-spe.github.io/09-containerization","title":"Prerequisites"},{"location":"quickstart/#use-the-cluster","text":"Request access to the VPN and to the required cluster, here is described how to do it. Configure your environment to use the VPN, following the guide received by email. Go to https://andromeda.apice.unibo.it Select an environment (i.e. a cluster) from the available ones on which launch containers Launch your Docker container following good practices . Warning Each machine is configured to run updates every Sunday at 1:30 AM. Sometimes, the update process requires a reboot of the machine. If this happens, the machine will be unavailable for a few minutes. If you are running a job, it will be interrupted and you will have to restart it. Please, follow the persistency good practices in order to save your experiments results in a persistent volume. Note The connection is provided by internal SSL certifiates, modern browsers try to block the connection to them. You have to explicitly declare, the first time you enter the URL described above, that you want to access the website.","title":"Use the cluster"},{"location":"explanation/docker-compose/","text":"Docker compose # https://unibo-spe.github.io/09-containerization/#/55","title":"Docker compose"},{"location":"explanation/docker-compose/#docker-compose","text":"https://unibo-spe.github.io/09-containerization/#/55","title":"Docker compose"},{"location":"explanation/docker-swarm/","text":"Docker Swarm # https://unibo-spe.github.io/09-containerization/#/73 Stacks # https://unibo-spe.github.io/09-containerization/#/58 Secrets # https://unibo-spe.github.io/09-containerization/#/60 Volumes # https://unibo-spe.github.io/09-containerization/#/32 Networks # https://unibo-spe.github.io/09-containerization/#/43","title":"Docker Swarm"},{"location":"explanation/docker-swarm/#docker-swarm","text":"https://unibo-spe.github.io/09-containerization/#/73","title":"Docker Swarm"},{"location":"explanation/docker-swarm/#stacks","text":"https://unibo-spe.github.io/09-containerization/#/58","title":"Stacks"},{"location":"explanation/docker-swarm/#secrets","text":"https://unibo-spe.github.io/09-containerization/#/60","title":"Secrets"},{"location":"explanation/docker-swarm/#volumes","text":"https://unibo-spe.github.io/09-containerization/#/32","title":"Volumes"},{"location":"explanation/docker-swarm/#networks","text":"https://unibo-spe.github.io/09-containerization/#/43","title":"Networks"},{"location":"explanation/jupyter-notebook/","text":"Jupyter notebooks # TODO Launch a Jupyter notebook server inside of the container # You can launch a Jupyter notebook inside of your custom container, to make it available from the outside you have to specify some additional parameters like the following ones: python3 -m jupyter notebook --ip 0.0.0.0 --allow-root","title":"Jupyter notebooks"},{"location":"explanation/jupyter-notebook/#jupyter-notebooks","text":"TODO","title":"Jupyter notebooks"},{"location":"explanation/jupyter-notebook/#launch-a-jupyter-notebook-server-inside-of-the-container","text":"You can launch a Jupyter notebook inside of your custom container, to make it available from the outside you have to specify some additional parameters like the following ones: python3 -m jupyter notebook --ip 0.0.0.0 --allow-root","title":"Launch a Jupyter notebook server inside of the container"},{"location":"explanation/portainer/","text":"Portainer Dashboard # TODO","title":"Portainer Dashboard"},{"location":"explanation/portainer/#portainer-dashboard","text":"TODO","title":"Portainer Dashboard"},{"location":"how-to/access-container/","text":"How to access deployed container # There are three ways with which you can access the deployed container: Access the container console through the Portainer dashboard (in the Console option of the container) Access the container through SSH connections, this requires that the container is configured to accept them. Configuring a web service inside of the container, for example, a Jupyter notebook. If you do this, you can access the service through the address http://<hostname>:<port> , where the hostname is the name of the node machine on which the container is running, and the port is the one you opened to connect to your web service inside of the container.","title":"How to access deployed container"},{"location":"how-to/access-container/#how-to-access-deployed-container","text":"There are three ways with which you can access the deployed container: Access the container console through the Portainer dashboard (in the Console option of the container) Access the container through SSH connections, this requires that the container is configured to accept them. Configuring a web service inside of the container, for example, a Jupyter notebook. If you do this, you can access the service through the address http://<hostname>:<port> , where the hostname is the name of the node machine on which the container is running, and the port is the one you opened to connect to your web service inside of the container.","title":"How to access deployed container"},{"location":"how-to/deploy-an-ssh-container/","text":"Deploy an Open SHH server container # The Portainer platform offers several pre-configured Stacks that can be deployed in the cluster, this is the case for example of Ubuntu SSH Server . How to use it # Click on the entry of the template you want to deploy in the cluster, and then add the required information inside the form. When you added all the information requires, you can finally click on Deploy the stack. The required informations are: Your Stack's name: which must follows the Good Practices . The username to log into the machine using SSH. Your SSH Public Key. You can create your public-private SSH keys by using the command ssh-keygen on unix-based systems. The hostname of the server on which the container will be deployed, choose one among the available ones in the cluster. A flag to enable sudo access to your SSH account into the container. Your persistent volume name. It will be mounted under the folder /persistent in the container. The port on which expose the service. Note Note that the exposed port should not be one of the frequently used by known services (take a look at this ). Warning If one of these information is missing, the container won't deploy correctly on the cluster. Warning If you want to save your data in the persistent volume, you have to save it under the /persistent folder, otherwise it will be lost after a container restart.","title":"Deploy an Open SHH server container"},{"location":"how-to/deploy-an-ssh-container/#deploy-an-open-shh-server-container","text":"The Portainer platform offers several pre-configured Stacks that can be deployed in the cluster, this is the case for example of Ubuntu SSH Server .","title":"Deploy an Open SHH server container"},{"location":"how-to/deploy-an-ssh-container/#how-to-use-it","text":"Click on the entry of the template you want to deploy in the cluster, and then add the required information inside the form. When you added all the information requires, you can finally click on Deploy the stack. The required informations are: Your Stack's name: which must follows the Good Practices . The username to log into the machine using SSH. Your SSH Public Key. You can create your public-private SSH keys by using the command ssh-keygen on unix-based systems. The hostname of the server on which the container will be deployed, choose one among the available ones in the cluster. A flag to enable sudo access to your SSH account into the container. Your persistent volume name. It will be mounted under the folder /persistent in the container. The port on which expose the service. Note Note that the exposed port should not be one of the frequently used by known services (take a look at this ). Warning If one of these information is missing, the container won't deploy correctly on the cluster. Warning If you want to save your data in the persistent volume, you have to save it under the /persistent folder, otherwise it will be lost after a container restart.","title":"How to use it"},{"location":"how-to/deploy-container/","text":"How to deploy a container # Users can directly deploy a container using the Portainer dashboard, in the Containers menu entry. After clicking on the Add container button, the user will be prompted to a container configuration page. After filling out the form, the user can click on the Deploy the container button to deploy the container. Two registries are currently available to pull images in Portainer: Docker Hub and Ascend Hub. The latter is configured to the Huawei registry, which contains the Ascend images. To better understand the configuration of a container, please refer to the Docker documentation . However, consider that if the container is restarted (e.g. after a reboot), the container will be restarted with the same configuration as the one provided in the form. This means that all the package installations made after the container creation will be lost. You can avoid this overcome in three ways: Use App Templates which are pre-configured to contain the most common packages for data-scientist use cases, but also allow you to install additional packages that will persist after the possible reboot. This is the most recommended way to work inside the cluster. Build your own image, and push it to Docker Hub registry. Then you can deploy the container using this image. This is the recommended way to work inside the cluster if you need to install a lot of packages, and these are not available in the App Templates. Consider allocating your volume as your home directory inside of the container, in this way all packages installed locally will persist after a reboot. This is not the recommended way to work inside the cluster; but works for the most simple use cases. Note Just remember that, in the third scenario, you need to specify that the installation is local for each package you install, for example, with pip you have to specify pip install --user <package> . If you encounter problems with the deployment, you can also ask cluster administrators to provide you with a pre-configured container that satisfies your needs. Note Inside of a Docker container you are logged as admin, and you can install whatever you want with the normal package manager (for instance, if the container is based on Ubuntu you can use sudo apt install <package> ). Note See docker volumes for more information about Docker volumes. App Templates # To ease the deployment of applications, several pre-configured Docker stacks are available inside of the Portainer dashboard. These templates are available in the App Templates menu entry, they are prepared to cover the most common use cases for data-scientist with the minimum configuration required. Secrets # If the template you chose uses a Jupyter Notebook, then it requires a Docker secret in order to configure a password for the notebook. To create a secret, you can go to the Secrets menu entry, and click on the Add secret button. Seealso See docker secrets for more information about Docker secrets.","title":"How to deploy a container"},{"location":"how-to/deploy-container/#how-to-deploy-a-container","text":"Users can directly deploy a container using the Portainer dashboard, in the Containers menu entry. After clicking on the Add container button, the user will be prompted to a container configuration page. After filling out the form, the user can click on the Deploy the container button to deploy the container. Two registries are currently available to pull images in Portainer: Docker Hub and Ascend Hub. The latter is configured to the Huawei registry, which contains the Ascend images. To better understand the configuration of a container, please refer to the Docker documentation . However, consider that if the container is restarted (e.g. after a reboot), the container will be restarted with the same configuration as the one provided in the form. This means that all the package installations made after the container creation will be lost. You can avoid this overcome in three ways: Use App Templates which are pre-configured to contain the most common packages for data-scientist use cases, but also allow you to install additional packages that will persist after the possible reboot. This is the most recommended way to work inside the cluster. Build your own image, and push it to Docker Hub registry. Then you can deploy the container using this image. This is the recommended way to work inside the cluster if you need to install a lot of packages, and these are not available in the App Templates. Consider allocating your volume as your home directory inside of the container, in this way all packages installed locally will persist after a reboot. This is not the recommended way to work inside the cluster; but works for the most simple use cases. Note Just remember that, in the third scenario, you need to specify that the installation is local for each package you install, for example, with pip you have to specify pip install --user <package> . If you encounter problems with the deployment, you can also ask cluster administrators to provide you with a pre-configured container that satisfies your needs. Note Inside of a Docker container you are logged as admin, and you can install whatever you want with the normal package manager (for instance, if the container is based on Ubuntu you can use sudo apt install <package> ). Note See docker volumes for more information about Docker volumes.","title":"How to deploy a container"},{"location":"how-to/deploy-container/#app-templates","text":"To ease the deployment of applications, several pre-configured Docker stacks are available inside of the Portainer dashboard. These templates are available in the App Templates menu entry, they are prepared to cover the most common use cases for data-scientist with the minimum configuration required.","title":"App Templates"},{"location":"how-to/deploy-container/#secrets","text":"If the template you chose uses a Jupyter Notebook, then it requires a Docker secret in order to configure a password for the notebook. To create a secret, you can go to the Secrets menu entry, and click on the Add secret button. Seealso See docker secrets for more information about Docker secrets.","title":"Secrets"},{"location":"how-to/request-access/","text":"How to request access to the platform # To get access to the platform you need to perform these operations: Request access to the VPN Request access to the cluster Request access to the VPN # - unibo credential users # If you are owner of a unibo credential you can directly request access to the VPN by sending an email to ciro.barbone@unibo.it . When you will be granted access you will receive an email with the instructions to connect to the VPN. Then, you can access the Portainer dashboard at https://andromeda.apice.unibo.it , where you can login with your unibo credential and run your experiments. - studio.unibo credential users # If you have a studio.unibo account, you must contact your supervisor that will request access to the VPN for you. When you will be granted access you will receive an email with the instructions to connect to the VPN. You'll not be able to directly access the Portainer Dashboard with your credential, your supervisor will provide you with a container on which you'll be able to access through its web service (or ssh service, depending on the container configuration). Request access to the cluster # After you are granted to use the VPN, you can access the Portainer dashboard at https://andromeda.apice.unibo.it , however, you will not be able to see any cluster. Cluster administrators will give you permission to access the appropriate cluster and will give you a persistent volume on which to save your experiments' results.","title":"How to request access to the platform"},{"location":"how-to/request-access/#how-to-request-access-to-the-platform","text":"To get access to the platform you need to perform these operations: Request access to the VPN Request access to the cluster","title":"How to request access to the platform"},{"location":"how-to/request-access/#request-access-to-the-vpn","text":"","title":"Request access to the VPN"},{"location":"how-to/request-access/#-unibo-credential-users","text":"If you are owner of a unibo credential you can directly request access to the VPN by sending an email to ciro.barbone@unibo.it . When you will be granted access you will receive an email with the instructions to connect to the VPN. Then, you can access the Portainer dashboard at https://andromeda.apice.unibo.it , where you can login with your unibo credential and run your experiments.","title":"- unibo credential users"},{"location":"how-to/request-access/#-studiounibo-credential-users","text":"If you have a studio.unibo account, you must contact your supervisor that will request access to the VPN for you. When you will be granted access you will receive an email with the instructions to connect to the VPN. You'll not be able to directly access the Portainer Dashboard with your credential, your supervisor will provide you with a container on which you'll be able to access through its web service (or ssh service, depending on the container configuration).","title":"- studio.unibo credential users"},{"location":"how-to/request-access/#request-access-to-the-cluster","text":"After you are granted to use the VPN, you can access the Portainer dashboard at https://andromeda.apice.unibo.it , however, you will not be able to see any cluster. Cluster administrators will give you permission to access the appropriate cluster and will give you a persistent volume on which to save your experiments' results.","title":"Request access to the cluster"}]}